# -*- coding: utf-8 -*-
"""FIN-NER-SENTIMENT-ANALYSIS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zvAsPQoCsv7_QbAbVvTWTcyr-3mty_7b
"""

from datasets import load_dataset
from evaluate import load
from transformers import AutoTokenizer, DataCollatorForTokenClassification
from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer
import numpy as np

dataset = load_dataset("yixuantt/FinEntity")


model_checkpoint = "bert-base-uncased"
tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)


original_label_list = sorted(list(set([tag for example in dataset["train"]["annotations"] for tag in [anno["tag"] for anno in example]])))
label_list = ["O"]
for label in original_label_list:
    label_list.append(f"B-{label}")
    label_list.append(f"I-{label}")

print(f"Label list (IOB2): {label_list}")
num_labels = len(label_list)
print(f"Number of labels: {num_labels}")


def tokenize_and_align_annotations(examples, label_list):
    tokenized_inputs = tokenizer(
        examples["content"],
        truncation=True,
        return_offsets_mapping=True,
        return_attention_mask=True,
        return_token_type_ids=True
    )

    labels = []

    iob2_label_list = ["O"]
    for label in label_list:
        iob2_label_list.append(f"B-{label}")
        iob2_label_list.append(f"I-{label}")
    iob2_label_map = {label: i for i, label in enumerate(iob2_label_list)}


    for i in range(len(examples["content"])):
        offset_mapping = tokenized_inputs.offset_mapping[i]
        annotations = examples["annotations"][i]
        text = examples["content"][i]
        sequence_labels = []


        char_labels = [iob2_label_map["O"]] * len(text)
        for annotation in annotations:
            annotation_start_char = annotation["start"]
            annotation_end_char = annotation["end"]
            label = annotation["tag"]
            if label in label_list:
                label_id_b = iob2_label_map[f"B-{label}"]
                label_id_i = iob2_label_map[f"I-{label}"]

                if annotation_start_char < len(char_labels):
                     char_labels[annotation_start_char] = label_id_b

                for char_idx in range(annotation_start_char + 1, annotation_end_char):
                    if char_idx < len(char_labels):
                        char_labels[char_idx] = label_id_i


        previous_word_id = None
        for j, word_id in enumerate(tokenized_inputs.word_ids(batch_index=i)):
            if word_id is None:
                sequence_labels.append(-100)
            elif word_id != previous_word_id:

                token_start_char, token_end_char = offset_mapping[j]
                if token_start_char < len(char_labels):
                     sequence_labels.append(char_labels[token_start_char])
                else:
                     sequence_labels.append(iob2_label_map["O"])
            else:

                sequence_labels.append(-100)
            previous_word_id = word_id

        labels.append(sequence_labels)

    tokenized_inputs["labels"] = labels
    tokenized_inputs.pop("offset_mapping")
    return tokenized_inputs



train_test_split_dataset = dataset["train"].train_test_split(test_size=0.2)
tokenized_dataset = train_test_split_dataset.map(tokenize_and_align_annotations, batched=True, fn_kwargs={"label_list": original_label_list})


data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)


model = AutoModelForTokenClassification.from_pretrained(
    model_checkpoint, num_labels=num_labels
)


metric = load("seqeval")

def compute_metrics(eval_preds):
    logits, labels = eval_preds
    predictions = np.argmax(logits, axis=-1)


    true_labels = [
        [label_list[l] for l in label if l != -100]
        for label in labels
    ]
    true_predictions = [
        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]
        for prediction, label in zip(predictions, labels)
    ]

    results = metric.compute(predictions=true_predictions, references=true_labels)
    return {
        "precision": results["overall_precision"],
        "recall": results["overall_recall"],
        "f1": results["overall_f1"],
        "accuracy": results["overall_accuracy"],
    }



training_args = TrainingArguments(
    output_dir="./finentity-ner-model",
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=5,
    weight_decay=0.01,
    logging_dir="./logs",
)


trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["test"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)


trainer.train()

trainer.save_model("./finentity-ner-model")
tokenizer.save_pretrained("./finentity-ner-model")

ner_pipeline = pipeline(
    "ner",
    model="./finentity-ner-model",
    tokenizer="./finentity-ner-model",
    aggregation_strategy="simple"
)

from transformers import AutoConfig, AutoModelForTokenClassification, AutoTokenizer, pipeline


label_list = ['O', 'B-Negative', 'I-Negative', 'B-Neutral', 'I-Neutral', 'B-Positive', 'I-Positive']
id2label = {i: l for i, l in enumerate(label_list)}
label2id = {l: i for i, l in enumerate(label_list)}


model_path = "./finentity-ner-model"
config = AutoConfig.from_pretrained(model_path, num_labels=len(label_list), id2label=id2label, label2id=label2id)
model = AutoModelForTokenClassification.from_pretrained(model_path, config=config)
tokenizer = AutoTokenizer.from_pretrained(model_path)


ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")


texts = [
    "Tesla shares rose 15% after 1 year",
    "Apple stocks rose 5% and Goldman Sachs stocks remain constant",
    "Goldman Sachs invested $500 million in India."
]


for text in texts:
    results = ner_pipeline(text)
    print(f"\nText: {text}")
    for entity in results:
        print(f"Entity: {entity['word']} | Label: {entity['entity_group']} | Score: {entity['score']:.4f}")